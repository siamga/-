{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>교차검증</h1>\n",
    "\n",
    "<h2>교차검증의 의미</h2>\n",
    "<h3>오버피팅</h3>\n",
    "학습데이터와 테스트 데이터로 나눠서 학습을 진행할 때, 훈련 데이터로만 만들어진\n",
    "훈련 횟수가 너무 많아 결과적으로 훈련 데이터에 대한 모델이 정확성이 너무 높아서 테스트 데이터를 예측하지 못하는 현상\n",
    "<br>-> 학습 횟수를 줄이는 방식으로 오버피팅을 방지 할 수 있겠지만 다른 방법은?</br>\n",
    "1.학습 데이터 세트 자체에 대해서 학습 데이터 세트와 검증 데이터 세트로 분할하여 \n",
    "반복학습을 하되 반복마다 계속 학습 데이터 자체를 학습,검증 세트로 나눠서 훈련한다.\n",
    "이 과정을 통해서 오버피팅의 확률을 줄인다\n",
    "<h3>=교차검증</h3>\n",
    "<br>교차 검증 후에 최종적으로 테스트 데이터로 확인한다</br>\n",
    "\n",
    "\n",
    "<h2>교차검증의 종류</h2>\n",
    "<h3>K-fold 교차 검증</h3>\n",
    "return과 yeields차이: 참고만 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.066772Z",
     "start_time": "2022-04-19T11:09:19.471970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불꽃 데이터 세트 크기: 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier #sklearn라이브러리의 tree 모듈에서 DecisionTreeClassifier 호출\n",
    "from sklearn.metrics import accuracy_score #정확도를 측정하는 함수 호출\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# class sklearn.model_selection.KFold(n_splits=5, *, shuffle=False, random_state=None)\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156) \n",
    "#\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "\n",
    "print('불꽃 데이터 세트 크기:',features.shape[0]) #.shape: numpy형식 데이터의 각각의 차원의 크기를 ndarray 형식으로 출력하는 함수\n",
    "#여기서는 단순히 행 개수만 알면 되기에 [0]으로 행 차원의 개수를 출력한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.097690Z",
     "start_time": "2022-04-19T11:09:21.070764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method _BaseKFold.split of KFold(n_splits=5, random_state=None, shuffle=False)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_iter = 0\n",
    "kfold.split(features)\n",
    "# kfold 내에서 데이터들을 train_index와 test_index로 구분되는 ndarray 데이터로 출력한다.\n",
    "\n",
    "kfold.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.145239Z",
     "start_time": "2022-04-19T11:09:21.100684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 교차 검증 정확도 1.0, 학습데이터 크기:120, 검증데이터 크기:30\n",
      "#1 검증 세트 인덱스[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "#2 교차 검증 정확도 1.0, 학습데이터 크기:120, 검증데이터 크기:30\n",
      "#2 검증 세트 인덱스[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "#3 교차 검증 정확도 1.0, 학습데이터 크기:120, 검증데이터 크기:30\n",
      "#3 검증 세트 인덱스[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "#4 교차 검증 정확도 1.0, 학습데이터 크기:120, 검증데이터 크기:30\n",
      "#4 검증 세트 인덱스[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "#5 교차 검증 정확도 1.0, 학습데이터 크기:120, 검증데이터 크기:30\n",
      "#5 검증 세트 인덱스[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " 평균 검증 정확도 1.0\n"
     ]
    }
   ],
   "source": [
    "for train_index , test_index in kfold.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    # print(features[30])\n",
    "\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "\n",
    "    accuracy = np.round(accuracy_score(y_test,pred))\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "\n",
    "    print(f'#{n_iter} 교차 검증 정확도 {accuracy}, 학습데이터 크기:{train_size}, 검증데이터 크기:{test_size}')\n",
    "    print(f'#{n_iter} 검증 세트 인덱스{test_index}')\n",
    "\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print(f'\\n 평균 검증 정확도 {np.mean(cv_accuracy)}')\n",
    "\n",
    "#어떻게 모델의 적정성을 이걸로 판단하나? 정확도로 적정성 파악 못한다면서\n",
    "#->kfold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.model_selection.StratifiedKFold\n",
    "class sklearn.model_selection.StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.207045Z",
     "start_time": "2022-04-19T11:09:21.148203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##교차검증:1\n",
      "학습 레이블 데이터 분포: 1    50\n",
      "2    20\n",
      "0    10\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: 1    50\n",
      "2    20\n",
      "0    10\n",
      "Name: label, dtype: int64\n",
      "##교차검증:2\n",
      "학습 레이블 데이터 분포: 0    40\n",
      "1    20\n",
      "2    20\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: 0    40\n",
      "1    20\n",
      "2    20\n",
      "Name: label, dtype: int64\n",
      "##교차검증:3\n",
      "학습 레이블 데이터 분포: 0    50\n",
      "1    30\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포: 0    50\n",
      "1    30\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#kfold의 문제점: 편향된 데이터의 경우 검증이 어렵다. ->예시사항\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris.keys()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df\n",
    "\n",
    "\n",
    "kfold = KFold(n_splits=3)\n",
    "\n",
    "n_iter=0\n",
    "for train_index, test_index in kfold.split(train_index, ):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[train_index]\n",
    "    print(f'##교차검증:{n_iter}')\n",
    "    print('학습 레이블 데이터 분포:',label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:', label_test.value_counts())\n",
    "\n",
    "#이 경우 학습 데이터와 검증 데이터가 전혀 겹쳐지지 않기 때문에 해당 \n",
    "#분류로 모델을 만들면 상당히 검증이 어렵다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.238959Z",
     "start_time": "2022-04-19T11:09:21.209040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "1 교차검증 0\n",
      "학습 레이블 데이터 분포 : 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "테스트 레이블 데이터 분포: 0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "2 교차검증 0\n",
      "학습 레이블 데이터 분포 : 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "테스트 레이블 데이터 분포: 0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "3 교차검증 0\n",
      "학습 레이블 데이터 분포 : 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "테스트 레이블 데이터 분포: 1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "iris_df = pd.DataFrame(data=iris.data, columns = iris.feature_names)\n",
    "iris_df['label']=iris.target\n",
    "iris_df['label'].value_counts()\n",
    "\n",
    "skt = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0 \n",
    "\n",
    "for train_index, test_index in skt.split(iris_df,iris_df['label']):\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    print(type(label_train))\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print(f'{n_iter} 교차검증 {0}')\n",
    "    print('학습 레이블 데이터 분포 :', label_train.value_counts())\n",
    "    print('테스트 레이블 데이터 분포:',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold클래스의 교차 검증 방법\n",
    "1. 폴드 세트 설정\n",
    "2. for 루프로 반복적인 학습/검증데이터 추출 및 학습, 예측 수행\n",
    "3. 폴드 세트 별 예측 성능을 평균해서 최종 성능 평가\n",
    "\n",
    "->일련의 과정을 cross_val_score로 간략화 할 수 있다.\n",
    "\n",
    "sklearn.model_selection.cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
    "\n",
    "estimator = 교차 검증에 사용할 모델 객체\n",
    "X = 독립변수\n",
    "y = 종속변수\n",
    "\n",
    "cv = kfold과정의 분할 개수 \n",
    "\n",
    "fit_params = 해당 부분에 데이터가 주어지면 모델에 사용되는 파라미터를 지정할 수 있다. 이것을 보고 GridSearchCV랑 별 차이가 없다고 볼 수 있는데 여기서는 \n",
    "모델에 사용되는 파라미터마다 하나의 데이터를 지정하는 것이고\n",
    "GridSearchCV의 경우 파라미터마다 여러개의 데이터를 지정 할 수 있다는 의미이다.\n",
    "\n",
    "\n",
    "\n",
    "->결과값으로 ndarray를 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.270876Z",
     "start_time": "2022-04-19T11:09:21.244944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도:  [0.98 0.94 0.98]\n",
      "평균 검증 정확도: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris, load_diabetes\n",
    "from sklearn import datasets, linear_model\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "scores = cross_val_score(dt_clf,data,label,scoring='accuracy',cv=3)\n",
    "print('교차 검증별 정확도: ',np.round(scores,4))\n",
    "print('평균 검증 정확도:',np.round(np.mean(scores),4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.model_selection.GridSearchCV\n",
    "\n",
    "GridSearchCV: 알고리즘에 적용되는 하이퍼 파라미터를 순차적으로 입력해서\n",
    "최적의 파라미터를 도출하는 방법을 제공\n",
    "여기서 데이터 분할 후 교차검증까지 진행된다.\n",
    "\n",
    "\n",
    "class sklearn.model_selection.GridSearchCV(estimator, param_grid, *,\n",
    " scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "\n",
    "estimate : 활용 알고리즘\n",
    "<br>param_grid: 적용 파라미터에 딕셔너리(키값=적용할 변수명,value값=적용할 데이터)\n",
    "<br>cv : 데이터 분할 수\n",
    "<br>scoring: 최적 모델 선정에서 기준이 되는 지표\n",
    "<br>-> why?: scoring값이 none값인데 최적의 모델이 선정 될 수 있는 것인가?\n",
    "<br>기본적으로 사용되는 모델이 결과 값에 대해서 score를 method 형태로 제공하면 \n",
    "<br>GridSearchCV는 해당 값을 일종의 디폴트 값으로 받아오기 때문이다.\n",
    "<br>만약 모델에서 자체적인 score에 대한 method를 제공하지 않는다면 오류가 난다.\n",
    "\n",
    "\n",
    "\n",
    "ex: DecisionTreeClassifier의 경우\n",
    "<br>max_depth와 min_samples_splits을 사용하는데 여기에 복수의 하이퍼 파라미터를 적용해 \n",
    "<br>이들 중 최적의 파라미터를 확인하고자 한다면 \n",
    "<br>param_grid에\n",
    "<br>{'max_dept':[],'min_sample_splits':[]} 형태로 작성하고\n",
    "<br>이때 \n",
    "<br>GridSearchCV는 estimate에 지정된 알고리즘을\n",
    "<br>len(max_dept)*len(min_sample_splits) 만큼 반복하여 개별 시도의 결과값을 도출한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.349820Z",
     "start_time": "2022-04-19T11:09:21.273866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터: {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.9750\n",
      "테스트 데이터 정확도: 0.966667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data,iris_data.target,test_size=0.2, random_state=121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'max_depth':[1,2,3],'min_samples_split':[2,3]}\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree,param_grid=parameters,cv=3)\n",
    "\n",
    "grid_dtree.fit(X_train,y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score',\\\n",
    "    'split0_test_score','split1_test_score','split2_test_score']]\n",
    "#->근디 여기는 왜 scoring을 지정 안했는디 최적 파라미터 같은게 나오냐....\n",
    "\n",
    "\n",
    "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))\n",
    "\n",
    "estimator = grid_dtree.best_estimator_\n",
    "pred = estimator.predict(X_test)\n",
    "print('테스트 데이터 정확도: {0:4f}'.format(accuracy_score(y_test,pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pima 인디언 당뇨병 예측을 DecisionTreeClassfier로 수행하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.787645Z",
     "start_time": "2022-04-19T11:09:21.358792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.627   50        1  \n",
      "1                       0.351   31        0  \n",
      "2                       0.672   32        1  \n",
      "3                       0.167   21        0  \n",
      "4                       2.288   33        1  \n",
      "..                        ...  ...      ...  \n",
      "763                     0.171   63        0  \n",
      "764                     0.340   27        0  \n",
      "765                     0.245   30        0  \n",
      "766                     0.349   47        1  \n",
      "767                     0.315   23        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 2}</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.663934</td>\n",
       "      <td>0.708397</td>\n",
       "      <td>0.023106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 3}</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.715447</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.647541</td>\n",
       "      <td>0.708370</td>\n",
       "      <td>0.030846</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004590</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 2}</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.703559</td>\n",
       "      <td>0.017160</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 6, 'min_samples_split': 3}</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.674797</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.703572</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 2}</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.697028</td>\n",
       "      <td>0.019486</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 3}</td>\n",
       "      <td>0.723577</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.691057</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.695402</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.004188      0.000747         0.001995        0.000001   \n",
       "1       0.004587      0.000798         0.001202        0.000410   \n",
       "2       0.004590      0.000485         0.001393        0.000485   \n",
       "3       0.004588      0.000800         0.001795        0.000399   \n",
       "4       0.004185      0.000401         0.001601        0.000493   \n",
       "5       0.004981      0.000613         0.001402        0.000503   \n",
       "\n",
       "  param_max_depth param_min_samples_split  \\\n",
       "0               5                       2   \n",
       "1               5                       3   \n",
       "2               6                       2   \n",
       "3               6                       3   \n",
       "4               7                       2   \n",
       "5               7                       3   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "0  {'max_depth': 5, 'min_samples_split': 2}           0.715447   \n",
       "1  {'max_depth': 5, 'min_samples_split': 3}           0.723577   \n",
       "2  {'max_depth': 6, 'min_samples_split': 2}           0.723577   \n",
       "3  {'max_depth': 6, 'min_samples_split': 3}           0.731707   \n",
       "4  {'max_depth': 7, 'min_samples_split': 2}           0.731707   \n",
       "5  {'max_depth': 7, 'min_samples_split': 3}           0.723577   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.715447           0.715447           0.731707           0.663934   \n",
       "1           0.715447           0.723577           0.731707           0.647541   \n",
       "2           0.682927           0.699187           0.723577           0.688525   \n",
       "3           0.674797           0.691057           0.723577           0.696721   \n",
       "4           0.691057           0.691057           0.699187           0.672131   \n",
       "5           0.691057           0.691057           0.699187           0.672131   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.708397        0.023106                1  \n",
       "1         0.708370        0.030846                2  \n",
       "2         0.703559        0.017160                4  \n",
       "3         0.703572        0.021087                3  \n",
       "4         0.697028        0.019486                5  \n",
       "5         0.695402        0.016658                6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "diabetes = pd.read_csv('./datasets/diabetes.csv')\n",
    "print(diabetes)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.iloc[:,1:8],diabetes.iloc[:,-1:],test_size=0.2, random_state=121)\n",
    "\n",
    "dtree= DecisionTreeClassifier()\n",
    "\n",
    "parameters = {'max_depth':[5,6,7],'min_samples_split':[2,3]}\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree,param_grid=parameters,cv=3)\n",
    "grid_dtree.fit(X_train,y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params','mean_test_score','rank_test_score',\\\n",
    "    'split0_test_score','split1_test_score','split2_test_score']]\n",
    "\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree,param_grid=parameters,cv=5)\n",
    "\n",
    "grid_dtree.fit(X_train,y_train)\n",
    "\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df\n",
    "# scores_df[['params','mean_test_score','rank_test_score',\\\n",
    "#     'split0_test_score','split1_test_score','split2_test_score']]\n",
    "\n",
    "\n",
    "\n",
    "# print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\n",
    "# print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))\n",
    "\n",
    "# estimator = grid_dtree.best_estimator_\n",
    "# pred = estimator.predict(X_test)\n",
    "# print('테스트 데이터 정확도: {0:4f}'.format(accuracy_score(y_test,pred)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 전처리는 알고리즘 만큼 중요하다.\n",
    "->why?: 데이터 분석에서 문자열은 입력값으로 허용하지 않기 때문이다.\n",
    "레이블 인코딩: 단일 실수로 문자열을 숫자에 대응시키는 방식의 인코딩\n",
    "원 핫 인코딩 : 벡터의 형태로 문자열을 숫자에 대응하는 방식의 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.803603Z",
     "start_time": "2022-04-19T11:09:21.793630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 4 5 3 3 2 2]\n",
      "['TV' '냉장고' '믹서' '선풍기' '전자렌지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "#레이블 인코딩\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "items = ['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "#LabelEncoder()로 클래스 생성 후 fit(), transform()으로 label 인코딩 수행\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "#인코딩 데이터를 items로 지정\n",
    "labels = encoder.transform(items)\n",
    "#labels 변수에 encoder에 지정된 items를 인코딩한 데이터 저장\n",
    "#굳이 fit으로 지정한 데이터를 transform에서 다시 지정하는 이유\n",
    "#->별 이유 없고 그냥 코드를 짤 때, 그렇게 하래요....\n",
    "print(labels)\n",
    "\n",
    "print(encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.preprocessing.OneHotEncoder\n",
    "\n",
    "class sklearn.preprocessing.OneHotEncoder(*, categories='auto', drop=None, sparse=True, dtype=<class 'numpy.float64'>, handle_unknown='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.851475Z",
     "start_time": "2022-04-19T11:09:21.806596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [3]\n",
      " [3]\n",
      " [2]\n",
      " [2]]\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자렌지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자렌지  item_컴퓨터\n",
       "0        1         0        0         0          0         0\n",
       "1        0         1        0         0          0         0\n",
       "2        0         0        0         0          1         0\n",
       "3        0         0        0         0          0         1\n",
       "4        0         0        0         1          0         0\n",
       "5        0         0        0         1          0         0\n",
       "6        0         0        1         0          0         0\n",
       "7        0         0        1         0          0         0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#원 핫 인코딩\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
    "\n",
    "#레이블 인코딩\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels =encoder.transform(items)\n",
    "\n",
    "labels = labels.reshape(-1,1)\n",
    "print(labels)\n",
    "\n",
    "#원핫 인코딩\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "\n",
    "print(oh_labels.toarray())\n",
    "oh_labels.shape\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'item':['TV','냉장고','전자렌지','컴퓨터','선풍기','선풍기','믹서','믹서']})\n",
    "pd.get_dummies(df)\n",
    "#pandas에서 지원하는 원핫 인코딩 api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "피쳐 스케일링 => 데이터의 분포를 보기 쉬운 분포로 전환하는 일\n",
    "\n",
    "StandardScaler => 평균0, 표준편차가 1인 정규분포 형태로 변환\n",
    "<br>MinMaxScaler => 데이터 값을 0에서 1까지의 값으로 전환한다.(최대값=1, 최소값=0 or-1)\n",
    "                <br>(음수가 있다면 -1~1까지의 값으로 전환한다.)\n",
    "                <br>일반적으로 minmax에서는 이상치를 제거하고 피쳐스케일링을 진행한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:21.899351Z",
     "start_time": "2022-04-19T11:09:21.858457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    1.006711\n",
       "sepal width (cm)     1.006711\n",
       "petal length (cm)    1.006711\n",
       "petal width (cm)     1.006711\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data = iris_data, columns=iris.feature_names)\n",
    "\n",
    "print(iris_df.mean())\n",
    "print(iris_df.var())\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "iris_df_scaled.mean()\n",
    "iris_df_scaled.var()\n",
    "\n",
    "\n",
    "####주의사항: 데이터 검증에서 학습데이터를 기반으로 정규화를 진행하게 될 것인데 이후에\n",
    "####         정규화에 대해 test데이터로 다시한번 fit을 하면 안된다\n",
    "# why? -> 이미 학습 데이터를 기반으로 데이터 분포에 대한 기준을 만든 것이고 \n",
    "#         여기서 추가적으로 test 데이터를 fit 하게되면 이 기준이 무너지게 된다.\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타이타닉 생존자 ML예측 구현\n",
    "<br>데이터 전처리\n",
    "    <br>*null처리</br>\n",
    "    <br>*불필요한 속성 제거</br>\n",
    "    <br>*인코딩 실행</br>\n",
    "<br>모델 학습 및 검증/예측/평가 </br>\n",
    "    <br>*결정트리, 랜덤 포레스트, 로지스틱 회귀</br>\n",
    "    <br>*kfold 교차 검증</br>\n",
    "    <br>*cross_val_score(), GridSearchCV() 수행</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:23.353708Z",
     "start_time": "2022-04-19T11:09:21.903338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "titanic_df = pd.read_csv('./datasets/train.csv')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:23.384622Z",
     "start_time": "2022-04-19T11:09:23.358692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:23.461418Z",
     "start_time": "2022-04-19T11:09:23.391615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.00</td>\n",
       "      <td>891.00</td>\n",
       "      <td>891.00</td>\n",
       "      <td>714.00</td>\n",
       "      <td>891.00</td>\n",
       "      <td>891.00</td>\n",
       "      <td>891.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2.31</td>\n",
       "      <td>29.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.38</td>\n",
       "      <td>32.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.35</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.84</td>\n",
       "      <td>14.53</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.81</td>\n",
       "      <td>49.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>20.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>38.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>80.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>512.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId  Survived  Pclass     Age   SibSp   Parch    Fare\n",
       "count       891.00    891.00  891.00  714.00  891.00  891.00  891.00\n",
       "mean        446.00      0.38    2.31   29.70    0.52    0.38   32.20\n",
       "std         257.35      0.49    0.84   14.53    1.10    0.81   49.69\n",
       "min           1.00      0.00    1.00    0.42    0.00    0.00    0.00\n",
       "25%         223.50      0.00    2.00   20.12    0.00    0.00    7.91\n",
       "50%         446.00      0.00    3.00   28.00    0.00    0.00   14.45\n",
       "75%         668.50      1.00    3.00   38.00    1.00    0.00   31.00\n",
       "max         891.00      1.00    3.00   80.00    8.00    6.00  512.33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:23.492335Z",
     "start_time": "2022-04-19T11:09:23.465406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(),inplace=True)\n",
    "titanic_df['Cabin'].fillna('N',inplace=True)\n",
    "titanic_df['Embarked'].fillna('N',inplace=True)\n",
    "titanic_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:23.523259Z",
     "start_time": "2022-04-19T11:09:23.495326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "성별 분포: \n",
      " male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "나이 분포: \n",
      " 29.699118    177\n",
      "24.000000     30\n",
      "22.000000     27\n",
      "18.000000     26\n",
      "28.000000     25\n",
      "            ... \n",
      "36.500000      1\n",
      "55.500000      1\n",
      "0.920000       1\n",
      "23.500000      1\n",
      "74.000000      1\n",
      "Name: Age, Length: 89, dtype: int64\n",
      "객실 분포: \n",
      " N              687\n",
      "C23 C25 C27      4\n",
      "G6               4\n",
      "B96 B98          4\n",
      "C22 C26          3\n",
      "              ... \n",
      "E34              1\n",
      "C7               1\n",
      "C54              1\n",
      "E36              1\n",
      "C148             1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "중간 기항지 분포: \n",
      " S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(titanic_df.columns)\n",
    "print('성별 분포: \\n',titanic_df['Sex'].value_counts())\n",
    "print('나이 분포: \\n',titanic_df['Age'].value_counts())\n",
    "print('객실 분포: \\n',titanic_df['Cabin'].value_counts())\n",
    "print('중간 기항지 분포: \\n',titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:23.554168Z",
     "start_time": "2022-04-19T11:09:23.527241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    N\n",
      "1    C\n",
      "2    N\n",
      "3    C\n",
      "4    N\n",
      "Name: Cabin, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "N    687\n",
       "C     59\n",
       "B     47\n",
       "D     33\n",
       "E     32\n",
       "A     15\n",
       "F     13\n",
       "G      4\n",
       "T      1\n",
       "Name: Cabin, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df['Cabin']=titanic_df['Cabin'].str[:1]\n",
    "print(titanic_df['Cabin'].head())\n",
    "titanic_df['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:23.867102Z",
     "start_time": "2022-04-19T11:09:23.560153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Sex', ylabel='Survived'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_df.groupby(['Sex','Survived']).count()\n",
    "sns.barplot(x='Sex',y='Survived',data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:24.335071Z",
     "start_time": "2022-04-19T11:09:23.870031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Pclass', ylabel='Survived'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass',y='Survived',hue='Sex',data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:24.365662Z",
     "start_time": "2022-04-19T11:09:24.338732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare  Cabin  Embarked  \n",
       "0         A/5 21171   7.2500      7         3  \n",
       "1          PC 17599  71.2833      2         0  \n",
       "2  STON/O2. 3101282   7.9250      7         3  \n",
       "3            113803  53.1000      2         3  \n",
       "4            373450   8.0500      7         3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features=['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:24.412032Z",
     "start_time": "2022-04-19T11:09:24.369649Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#null값 처리\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "#불필요한 feature값 삭제\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "#레이블 인코딩 수행\n",
    "def format_features(df):\n",
    "    df['Cabin']=df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "#작성 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df=format_features(df)\n",
    "    return df\n",
    "\n",
    "titanic_df = pd.read_csv('./datasets/train.csv')\n",
    "\n",
    "transform_features(titanic_df).to_csv('ad_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:24.426996Z",
     "start_time": "2022-04-19T11:09:24.415030Z"
    }
   },
   "outputs": [],
   "source": [
    "#타이타닉 생존자 ML 구현 \n",
    "## 1.데이터 전처리\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived',axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_titanic_df,y_titanic_df,\n",
    "                                                 test_size=0.2,random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:25.023276Z",
     "start_time": "2022-04-19T11:09:24.430987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df의 정확도: 0.7877\n",
      "rf의 정확도: 0.8547\n",
      "lr의 정확도: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## 2. 모델 유형별 정확도 측정-> 모델 선정에는 정확도 말고 다양한 요소가 있으나\n",
    "##    지금은 편의상 정확도만 사용해서 측정하자.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#3가지 알고리즘 선정 -> 각각의 알고리즘에 해당하는 객체(class) 생성\n",
    "df_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "#개별 알고리즘의 학습\n",
    "df_clf.fit(X_train,y_train)\n",
    "df_pred = df_clf.predict(X_test)\n",
    "print('df의 정확도:{0: .4f}'.format(accuracy_score(y_test,df_pred)))\n",
    "\n",
    "rf_clf.fit(X_train,y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('rf의 정확도:{0: .4f}'.format(accuracy_score(y_test,rf_pred)))\n",
    "\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('lr의 정확도:{0: .4f}'.format(accuracy_score(y_test,lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:26.458440Z",
     "start_time": "2022-04-19T11:09:25.028262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(random_state=156) 모델 정확도\n",
      "교차검증0 정확도: 0.7542\n",
      "교차검증1 정확도: 0.7640\n",
      "교차검증2 정확도: 0.7865\n",
      "교차검증3 정확도: 0.7584\n",
      "교차검증4 정확도: 0.8371\n",
      "평균 정확도: 0.7801\n",
      "RandomForestClassifier(random_state=11) 모델 정확도\n",
      "교차검증0 정확도: 0.7933\n",
      "교차검증1 정확도: 0.8090\n",
      "교차검증2 정확도: 0.8371\n",
      "교차검증3 정확도: 0.7753\n",
      "교차검증4 정확도: 0.8596\n",
      "평균 정확도: 0.8148\n",
      "LogisticRegression() 모델 정확도\n",
      "교차검증0 정확도: 0.8045\n",
      "교차검증1 정확도: 0.7809\n",
      "교차검증2 정확도: 0.7753\n",
      "교차검증3 정확도: 0.7472\n",
      "교차검증4 정확도: 0.8146\n",
      "평균 정확도: 0.7845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\LG\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "## KFold교차검증을 통한 모델 적합성 평가 함수 \n",
    "\n",
    "def exec_kfold(clf,folds=5):\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores=[]\n",
    "    print('{} 모델 정확도'.format(clf))\n",
    "    \n",
    "    for iter_count, (train_index,test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "# enumerate(): 지정된 데이터에 대해서 인덱스와 데이터를 묶어서 튜플 형태로 출력하는 함수로\n",
    "# 여기서는 iter_count,(train_index,test_index)로 enumerate(kfold.split(X_titanic_df))를\n",
    "# 출력해서 인덱스는 iter_count에 저장되고 데이터는 (train_index,test_index)로 저장된다.\n",
    "# 여기서 kfold.split(X_titanic_df)는 지정된 데이터를 train과 test로 나눈 값의 인덱스를 \n",
    "# 리스트로 만들어서 array 형식으로 묶은 데이터로 반환하는 함수인데\n",
    "# 여기서 개별 array 앞쪽의 리스트는 train데이터의 인덱스, \n",
    "# 뒤쪽의 리스트는 test데이터를 의미한다.\n",
    "## kfold.split의 array 데이터 결과값 확인용\n",
    "## kfold = KFold()\n",
    "## for a in kfold.split(X_titanic_df):\n",
    "##    print(a)\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index] \n",
    "        \n",
    "        clf.fit(X_train,y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test,predictions)\n",
    "        scores.append(accuracy)\n",
    "        print('교차검증{} 정확도: {:.4f}'.format(iter_count, accuracy))\n",
    "    \n",
    "    mean_score = np.mean(scores)\n",
    "    print('평균 정확도: {:.4f}'.format(mean_score))\n",
    "\n",
    "exec_kfold(dt_clf, folds=5)\n",
    "exec_kfold(rf_clf,folds=5)\n",
    "exec_kfold(lr_clf,folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:26.534456Z",
     "start_time": "2022-04-19T11:09:26.461433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(random_state=156) 모델 정확도\n",
      "교차검증 0 정확도: 0.7486\n",
      "교차검증 1 정확도: 0.7697\n",
      "교차검증 2 정확도: 0.7978\n",
      "교차검증 3 정확도: 0.7809\n",
      "교차검증 4 정확도: 0.8202\n",
      "평균 정확도: 0.7834\n"
     ]
    }
   ],
   "source": [
    "# cross_val_score을 이용한 모델 교차 검증의 간략화\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_titanic_df,y_titanic_df,cv=5)\n",
    "print(dt_clf,'모델 정확도')\n",
    "for iter_count,accuracy in enumerate(scores):\n",
    "    print('교차검증 {} 정확도: {:.4f}'.format(iter_count,accuracy))\n",
    "print('평균 정확도: {:.4f}'.format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:27.657615Z",
     "start_time": "2022-04-19T11:09:26.536455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.7992\n",
      "테스트 세트에서 DecisionTreeClassifier 정확도:0.8715\n"
     ]
    }
   ],
   "source": [
    "#GridSearchCV를 활용한 모델의 파라미터별 교차 검증의 간략화\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth':[2,3,5,10],\n",
    "             'min_samples_split':[2,3,5],'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf , param_grid=parameters, cv=5)\n",
    "grid_dclf.fit(X_train,y_train)\n",
    "\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:',grid_dclf.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {:.4f}'.format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,dpredictions)\n",
    "print('테스트 세트에서 DecisionTreeClassifier 정확도:{:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-19T11:09:28.657700Z",
     "start_time": "2022-04-19T11:09:27.669546Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=179 does not match number of samples=712",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m X_train, X_test, y_test, y_train \u001b[38;5;241m=\u001b[39m train_test_split(X,y,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m)\n\u001b[0;32m     14\u001b[0m pipeline\u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m,StandardScaler()),(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrfc\u001b[39m\u001b[38;5;124m'\u001b[39m,DecisionTreeClassifier())])\n\u001b[1;32m---> 16\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy_score(y_test,y_pred))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    393\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 394\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py:299\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_features_ \u001b[38;5;241m=\u001b[39m max_features\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m!=\u001b[39m n_samples:\n\u001b[1;32m--> 299\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m does not match number of samples=\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(y), n_samples)\n\u001b[0;32m    302\u001b[0m     )\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_weight_fraction_leaf \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_weight_fraction_leaf must in [0, 0.5]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of labels=179 does not match number of samples=712"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "X= titanic_df.drop('Survived',axis=1)\n",
    "y = titanic_df['Survived']\n",
    "\n",
    "X_train, X_test, y_test, y_train = train_test_split(X,y,test_size=0.2,random_state=11)\n",
    "\n",
    "pipeline= Pipeline([('scaler',StandardScaler()),('rfc',DecisionTreeClassifier())])\n",
    "\n",
    "pipeline.fit(X_train,y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(precision_score(y_test,y_pred))\n",
    "print(recall_score(y_test,y_pred))\n",
    "GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "331bd23392a92086fd590ecf5a213fcdd1f8f4c6ba45d0d0d004749536b030d7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
